import json
import qdrant_client
from qdrant_client.models import PointStruct, VectorParams, Distance
import voyageai
import uuid
import re
import logging
from datetime import datetime
from tqdm import tqdm
import os

# Configuration
VOYAGE_API_KEY = "pa-gPu9JZffTtb0O57mU8ZNtCzWBrQ7dDRy_7M_f6Cr8br"
voyage_client = voyageai.Client(api_key=VOYAGE_API_KEY)

QDRANT_HOST = "13.39.82.37"
QDRANT_PORT = 6333
EMBEDDING_DIM = 1024

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class GuideProcessor:
    """Processeur optimis√© pour l'embedding des guides avec enrichissement contextuel"""
    
    def __init__(self):
        self.qdrant_client = qdrant_client.QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)
        self.collection_name = "cgi_annexe_optimized"
        self.points = []
        
    def ensure_collection_exists(self):
        """V√©rifie que la collection existe, la cr√©e si n√©cessaire"""
        try:
            # V√©rifier si la collection existe
            collection_info = self.qdrant_client.get_collection(self.collection_name)
            logger.info(f"Collection {self.collection_name} existe d√©j√† avec {collection_info.points_count} points")
        except:
            # La collection n'existe pas, on la cr√©e
            self.qdrant_client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(size=EMBEDDING_DIM, distance=Distance.COSINE)
            )
            logger.info(f"Collection {self.collection_name} cr√©√©e")
    
    def process_guide_entry(self, entry_data, doc_index):
        """Traite une entr√©e de guide avec enrichissement contextuel"""
        doc_id = str(uuid.uuid4())
        
        # Extraire les infos de base
        document = entry_data.get("document", "")
        objet = entry_data.get("objet", "")
        contenu = entry_data.get("contenu", "")
        
        # Extraire les infos structur√©es sp√©cifiques aux guides
        chapitre = entry_data.get("chapitre", "")
        nom_chapitre = entry_data.get("nom_chapitre", "")
        partie = entry_data.get("partie", "")
        nom_partie = entry_data.get("nom_partie", "")
        sous_partie = entry_data.get("sous_partie", "")
        nom_sous_partie = entry_data.get("nom_sous_partie", "")
        introduction = entry_data.get("introduction", "")
        
        # Utiliser l'introduction si le contenu est vide
        main_content = contenu if contenu else introduction
        
        if not main_content or not main_content.strip():
            logger.warning(f"Entr√©e {doc_index} vide, ignor√©e")
            return None
        
        # Extraire les informations d√©taill√©es du document
        doc_info = self._extract_document_info(document)
        
        # ENRICHISSEMENT CONTEXTUEL SP√âCIFIQUE AUX GUIDES
        enriched_text_parts = []
        
        # 1. M√©tadonn√©es structur√©es
        enriched_text_parts.append(f"Type de document: guide fiscal")
        enriched_text_parts.append(f"Guide: {doc_info['titre']}")
        enriched_text_parts.append(f"R√©gime fiscal: {doc_info['regime']}")
        enriched_text_parts.append(f"Th√®me principal: {doc_info['theme']}")
        
        # 2. Structure hi√©rarchique
        if chapitre:
            enriched_text_parts.append(f"Chapitre: {chapitre} - {nom_chapitre}")
        if partie:
            enriched_text_parts.append(f"Partie: {partie} - {nom_partie}")
        if sous_partie:
            enriched_text_parts.append(f"Sous-partie: {sous_partie} - {nom_sous_partie}")
        if objet:
            enriched_text_parts.append(f"Objet: {objet}")
        
        # 3. Extraction et enrichissement des concepts cl√©s
        key_concepts = self._extract_key_concepts(main_content, doc_info['regime'])
        if key_concepts:
            enriched_text_parts.append(f"Concepts cl√©s: {', '.join(key_concepts)}")
        
        # 4. Enrichissement sp√©cifique par r√©gime
        regime_enrichment = self._get_regime_enrichment(main_content, doc_info['regime'])
        if regime_enrichment:
            enriched_text_parts.extend(regime_enrichment)
        
        # 5. R√©f√©rences l√©gales
        legal_refs = self._extract_legal_references(main_content)
        if legal_refs:
            enriched_text_parts.append(f"R√©f√©rences l√©gales: {', '.join(legal_refs)}")
        
        # 6. Contenu principal
        enriched_text_parts.append(f"Contenu complet: {main_content}")
        
        # Cr√©er le texte enrichi final
        enriched_text = "\n\n".join(enriched_text_parts)
        
        # G√©n√©rer l'embedding
        try:
            result = voyage_client.embed(
                [enriched_text], 
                model="voyage-law-2",
                input_type="document"
            )
            embedding = result.embeddings[0]
        except Exception as e:
            logger.error(f"Erreur embedding entr√©e {doc_index}: {e}")
            return None
        
        # Extraire des m√©tadonn√©es suppl√©mentaires pour la recherche
        search_keywords = self._generate_search_keywords(document, main_content, doc_info, objet)
        
        # Cr√©er le point Qdrant
        point = PointStruct(
            id=doc_id,
            vector=embedding,
            payload={
                # Infos de base
                "type": "guide",
                "document": document,
                "objet": objet,
                "contenu": main_content,
                
                # Structure hi√©rarchique
                "chapitre": chapitre,
                "nom_chapitre": nom_chapitre,
                "partie": partie,
                "nom_partie": nom_partie,
                "sous_partie": sous_partie,
                "nom_sous_partie": nom_sous_partie,
                "introduction": introduction,
                
                # M√©tadonn√©es extraites
                "titre_guide": doc_info["titre"],
                "regime_fiscal": doc_info["regime"],
                "theme": doc_info["theme"],
                "categorie": doc_info["categorie"],
                
                # M√©tadonn√©es enrichies
                "search_keywords": search_keywords,
                "key_concepts": key_concepts,
                "legal_references": legal_refs,
                "enriched_text": enriched_text,  # Garder pour debug
                
                # Flags sp√©cifiques aux guides
                "has_auto_entrepreneur": "auto-entrepreneur" in main_content.lower(),
                "has_cpu": "cpu" in main_content.lower() or "contribution professionnelle unique" in main_content.lower(),
                "has_montant": bool(re.search(r'\d+.*dirhams?', main_content.lower())),
                "has_pourcentage": bool(re.search(r'\d+\s*%', main_content)),
                "has_seuil": "seuil" in main_content.lower(),
                "has_exoneration": "exon√©ration" in main_content.lower(),
                "has_declaration": "d√©claration" in main_content.lower(),
                "has_barid_al_maghrib": "barid al-maghrib" in main_content.lower(),
                
                # M√©tadonn√©es techniques
                "doc_index": doc_index,
                "indexed_at": datetime.now().isoformat()
            }
        )
        
        return point
    
    def _extract_document_info(self, document):
        """Extraction des informations du document guide"""
        doc_info = {
            "titre": "",
            "regime": "",
            "theme": "",
            "categorie": ""
        }
        
        document_lower = document.lower()
        
        # Extraire le titre
        if "guide -" in document_lower:
            doc_info["titre"] = document.split("Guide - ")[1].strip()
        elif "guide pratique" in document_lower:
            doc_info["titre"] = document.strip()
        
        # D√©terminer le r√©gime fiscal
        if "auto-entrepreneur" in document_lower:
            doc_info["regime"] = "Auto-entrepreneur"
            doc_info["theme"] = "R√©gime fiscal simplifi√©"
            doc_info["categorie"] = "Micro-entreprise"
        elif "cpu" in document_lower or "contribution professionnelle unique" in document_lower:
            doc_info["regime"] = "CPU"
            doc_info["theme"] = "Contribution professionnelle unique"
            doc_info["categorie"] = "R√©gime forfaitaire"
        else:
            doc_info["regime"] = "G√©n√©ral"
            doc_info["theme"] = "R√©glementation fiscale"
            doc_info["categorie"] = "Guide g√©n√©ral"
        
        return doc_info
    
    def _extract_key_concepts(self, contenu, regime):
        """Extrait les concepts cl√©s du contenu selon le r√©gime"""
        concepts = []
        contenu_lower = contenu.lower()
        
        # Concepts communs
        common_concepts = {
            "chiffre d'affaires": r"chiffre\s+d[''']affaires?",
            "d√©claration": r"d√©claration",
            "imp√¥t sur le revenu": r"imp√¥t\s+sur\s+le\s+revenu",
            "exon√©ration": r"exon√©ration",
            "seuil": r"seuil",
            "taux": r"taux",
        }
        
        # Concepts sp√©cifiques par r√©gime
        if regime == "Auto-entrepreneur":
            specific_concepts = {
                "RNAE": r"rnae|registre\s+national",
                "Barid Al-Maghrib": r"barid\s+al[\-\s]maghrib",
                "ICE": r"ice|identifiant\s+commun",
                "versement trimestriel": r"trimestriel",
                "radiation": r"radiation",
            }
        elif regime == "CPU":
            specific_concepts = {
                "contribution professionnelle unique": r"contribution\s+professionnelle\s+unique",
                "b√©n√©fice forfaitaire": r"b√©n√©fice\s+forfaitaire",
                "coefficient": r"coefficient",
                "droit compl√©mentaire": r"droit\s+compl√©mentaire",
                "assurance maladie": r"assurance\s+maladie",
            }
        else:
            specific_concepts = {}
        
        # Combiner tous les concepts
        all_concepts = {**common_concepts, **specific_concepts}
        
        for concept, pattern in all_concepts.items():
            if re.search(pattern, contenu_lower):
                concepts.append(concept)
        
        # Extraire les montants
        amounts = re.findall(r'\d+(?:[\s.]\d+)*\s*(?:dirhams?|dh)', contenu_lower)
        concepts.extend([f"montant: {amt}" for amt in amounts[:3]])
        
        # Extraire les pourcentages
        percentages = re.findall(r'\d+\s*%', contenu)
        concepts.extend([f"taux: {pct}" for pct in percentages[:2]])
        
        return list(set(concepts))[:15]
    
    def _get_regime_enrichment(self, contenu, regime):
        """Enrichissement sp√©cifique par r√©gime fiscal"""
        enrichment = []
        contenu_lower = contenu.lower()
        
        if regime == "Auto-entrepreneur":
            enrichment.extend([
                "Secteur: micro-entreprise, auto-emploi, simplification fiscale",
                "Organisme: Barid Al-Maghrib, RNAE",
                "Avantages: dispense comptabilit√©, exon√©ration TP"
            ])
        elif regime == "CPU":
            enrichment.extend([
                "Secteur: contribution unique, r√©gime forfaitaire",
                "Composantes: IR + TP + TSC + couverture sociale",
                "Transition: remplacement b√©n√©fice forfaitaire"
            ])
        
        return enrichment
    
    def _extract_legal_references(self, contenu):
        """Extrait les r√©f√©rences l√©gales"""
        references = []
        
        # Articles du CGI
        cgi_refs = re.findall(r'article\s+(\d+(?:[\-\.]\w+)*)', contenu, re.IGNORECASE)
        references.extend([f"CGI art. {ref}" for ref in cgi_refs])
        
        # Lois de finances
        lf_refs = re.findall(r'loi\s+de\s+finances\s+n¬∞\s*([\d\-\.]+)', contenu, re.IGNORECASE)
        references.extend([f"LF {ref}" for ref in lf_refs])
        
        # Lois g√©n√©rales
        law_refs = re.findall(r'loi\s+n¬∞\s*([\d\-\.]+)', contenu, re.IGNORECASE)
        references.extend([f"Loi {ref}" for ref in law_refs])
        
        # D√©crets
        decree_refs = re.findall(r'd√©cret\s+n¬∞\s*([\d\-\.]+)', contenu, re.IGNORECASE)
        references.extend([f"D√©cret {ref}" for ref in decree_refs])
        
        # Dahirs
        dahir_refs = re.findall(r'dahir\s+n¬∞\s*([\d\-\.]+)', contenu, re.IGNORECASE)
        references.extend([f"Dahir {ref}" for ref in dahir_refs])
        
        return list(set(references))[:10]
    
    def _generate_search_keywords(self, document, contenu, doc_info, objet):
        """G√©n√®re des mots-cl√©s optimis√©s pour la recherche"""
        keywords = []
        
        # Mots du titre/objet
        if objet:
            objet_words = [w for w in objet.lower().split() if len(w) > 3]
            keywords.extend(objet_words[:5])
        
        # Type et r√©gime
        keywords.extend(["guide", doc_info['regime'].lower(), doc_info['theme'].lower()])
        
        # Termes sp√©cialis√©s selon le r√©gime
        if doc_info['regime'] == "Auto-entrepreneur":
            specialized_terms = [
                "auto-entrepreneur", "rnae", "barid", "ice", "trimestriel", 
                "radiation", "inscription", "statut", "exon√©ration", "dispense"
            ]
        elif doc_info['regime'] == "CPU":
            specialized_terms = [
                "cpu", "contribution", "professionnelle", "unique", "forfaitaire",
                "coefficient", "compl√©mentaire", "assurance", "maladie", "transition"
            ]
        else:
            specialized_terms = [
                "fiscal", "imp√¥t", "taxe", "d√©claration", "r√©gime", "contribuable"
            ]
        
        for term in specialized_terms:
            if term in contenu.lower():
                keywords.append(term)
        
        return list(set(keywords))[:20]
    
    def process_all_guides(self, guides):
        """Traite toutes les entr√©es de guides"""
        logger.info(f"Traitement de {len(guides)} entr√©es de guides...")
        
        # S'assurer que la collection existe
        self.ensure_collection_exists()
        
        # Traiter chaque entr√©e
        for i, guide in enumerate(tqdm(guides, desc="Traitement des guides")):
            point = self.process_guide_entry(guide, i)
            if point:
                self.points.append(point)
        
        # Indexer tous les points
        if self.points:
            logger.info(f"Ajout de {len(self.points)} nouvelles entr√©es...")
            
            # Indexer par batch
            batch_size = 20
            for i in range(0, len(self.points), batch_size):
                batch = self.points[i:i+batch_size]
                try:
                    self.qdrant_client.upsert(
                        collection_name=self.collection_name,
                        points=batch
                    )
                    logger.info(f"Batch {i//batch_size + 1} index√©")
                except Exception as e:
                    logger.error(f"Erreur indexation batch: {e}")
            
            # V√©rifier le total final
            collection_info = self.qdrant_client.get_collection(self.collection_name)
            logger.info(f"‚úÖ Collection mise √† jour avec {collection_info.points_count} entr√©es au total")
        
        return len(self.points)

def main():
    """Script principal pour indexer les guides"""
    logger.info("üöÄ D√©marrage de l'indexation des guides")
    
    # Charger les donn√©es
    with open("/Users/ayoub/Documents/GitHub/FB-Ahmed/annexes/CGI/JSON/guide.json", "r", encoding="utf-8") as f:
        guide_data = json.load(f)
    
    logger.info(f"‚úÖ {len(guide_data)} entr√©es charg√©es")
    
    # Cr√©er le processeur
    processor = GuideProcessor()
    
    # Traiter toutes les entr√©es
    count = processor.process_all_guides(guide_data)
    
    logger.info(f"‚úÖ Indexation termin√©e: {count} nouvelles entr√©es ajout√©es")
    
    # Sauvegarder les stats
    stats = {
        "total_entries": len(guide_data),
        "new_indexed_entries": count,
        "collection_name": processor.collection_name,
        "timestamp": datetime.now().isoformat()
    }
    
    with open("guide_indexing_stats.json", "w", encoding="utf-8") as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    logger.info("‚úÖ Stats sauvegard√©es dans guide_indexing_stats.json")

if __name__ == "__main__":
    main()